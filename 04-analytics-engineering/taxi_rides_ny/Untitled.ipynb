{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f899d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.38-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/first_one/.pyenv/versions/3.13.1/envs/de_zoomcamp/lib/python3.13/site-packages (from sqlalchemy) (4.12.2)\n",
      "Downloading SQLAlchemy-2.0.38-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (615 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.6/615.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.1.1 sqlalchemy-2.0.38\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a6c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-01.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "1428503544\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-02.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "108225919\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-03.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "93980700\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-04.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "123008542\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-05.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "131387979\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-06.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "127591175\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-07.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "123323044\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-08.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "119173810\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-09.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "78714715\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "119796110\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-11.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "118688353\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-12.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "128830380\n",
      "Data loaded successfully into the green_taxies table!\n",
      "Downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2020-01.csv.gz...\n",
      "Table fhv_taxies created (or already exists).\n",
      "127818845\n"
     ]
    },
    {
     "ename": "BadCopyFileFormat",
     "evalue": "missing data for column \"pickup_datetime\"\nCONTEXT:  COPY fhv_taxies, line 101142: \"B02765\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadCopyFileFormat\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2020\u001b[39m]:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m13\u001b[39m))]:\n\u001b[0;32m--> 136\u001b[0m             \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolor\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_tripdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmonth\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#                         https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 125\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(filename, color)\u001b[0m\n\u001b[1;32m    122\u001b[0m csv_copy_io \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mStringIO(csv_data)\n\u001b[1;32m    124\u001b[0m copy_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOPY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_taxies FROM STDIN WITH CSV HEADER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_expert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_copy_io\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m    128\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mBadCopyFileFormat\u001b[0m: missing data for column \"pickup_datetime\"\nCONTEXT:  COPY fhv_taxies, line 101142: \"B02765\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filename: str, color):\n",
    "    release_api_url = f\"https://api.github.com/repos/DataTalksClub/nyc-tlc-data/releases/tags/{color}\"\n",
    "    response = requests.get(release_api_url)\n",
    "    response.raise_for_status()  # Raise error for failed requests\n",
    "    release_info = response.json()\n",
    "\n",
    "    # Step 2: Find the asset named \"green_tripdata_2019-01.csv.gz\"\n",
    "    asset_url = None\n",
    "    for asset in release_info.get('assets', []):\n",
    "        if asset.get('name') == filename:\n",
    "            asset_url = asset.get('browser_download_url')\n",
    "            break\n",
    "\n",
    "    if not asset_url:\n",
    "        raise Exception(f\"Asset {filename} not found in the release.\")\n",
    "\n",
    "    print(f\"Downloading {asset_url}...\")\n",
    "    file_response = requests.get(asset_url)\n",
    "    file_response.raise_for_status()\n",
    "\n",
    "    # Step 3: Decompress the downloaded gzip file to get CSV content\n",
    "    with gzip.open(io.BytesIO(file_response.content), 'rt') as f:\n",
    "        csv_data = f.read()\n",
    "\n",
    "    # Step 4: Connect to the PostgreSQL database on localhost:5432 (database \"test\")\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"test\",\n",
    "        user=\"test\",  # adjust username as needed\n",
    "        password=\"test\",\n",
    "        host=\"localhost\",\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Step 5: Create the table \"green_taxies\" if it doesn't exist\n",
    "    # Use Python's csv module to read the header row from the CSV data\n",
    "    csv_header_io = io.StringIO(csv_data)\n",
    "    reader = csv.reader(csv_header_io)\n",
    "    header = next(reader)  # Extract header row as list of column names\n",
    "\n",
    "    # Build a CREATE TABLE statement with each column as TEXT.\n",
    "    # Note: In production you might want to define more specific types.\n",
    "    columns_sql = \", \".join([f'\"{col}\" TEXT' for col in header])\n",
    "    if color == \"green\":\n",
    "        create_table_sql = f\"\"\"\n",
    "\n",
    "        CREATE TABLE if not exists public.green_taxies (\n",
    "            \"VendorID\" int4 NULL,\n",
    "            lpep_pickup_datetime timestamp NULL,\n",
    "            lpep_dropoff_datetime timestamp NULL,\n",
    "            store_and_fwd_flag varchar(50) NULL,\n",
    "            \"RatecodeID\" text NULL,\n",
    "            \"PULocationID\" int4 NULL,\n",
    "            \"DOLocationID\" text NULL,\n",
    "            passenger_count int4 NULL,\n",
    "            trip_distance float4 NULL,\n",
    "            fare_amount float4 NULL,\n",
    "            extra float4 NULL,\n",
    "            mta_tax float4 NULL,\n",
    "            tip_amount float4 NULL,\n",
    "            tolls_amount float4 NULL,\n",
    "            ehail_fee float(50) NULL,\n",
    "            improvement_surcharge float4 NULL,\n",
    "            total_amount float4 NULL,\n",
    "            payment_type float4 NULL,\n",
    "            trip_type float4 NULL,\n",
    "            congestion_surcharge varchar(50) NULL\n",
    "        );\n",
    "        \"\"\"\n",
    "    elif color == \"fhv\":\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE if not exists public.fhv_taxies (\n",
    "            dispatching_base_num varchar(50) NULL,\n",
    "            pickup_datetime timestamp NULL,\n",
    "            \"dropOff_datetime\" timestamp NULL,\n",
    "            \"PUlocationID\" int NULL,\n",
    "            \"DOlocationID\" int NULL,\n",
    "            \"SR_Flag\" varchar(50) NULL,\n",
    "            \"Affiliated_base_number\" varchar(50) NULL\n",
    "        );\n",
    "        \"\"\"\n",
    "    else:\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE if not exists public.yellow_taxies (\n",
    "            \"VendorID\" int NULL,\n",
    "            tpep_pickup_datetime timestamp NULL,\n",
    "            tpep_dropoff_datetime timestamp NULL,\n",
    "            passenger_count int NULL,\n",
    "            trip_distance float NULL,\n",
    "            \"RatecodeID\" int NULL,\n",
    "            store_and_fwd_flag varchar(50) NULL,\n",
    "            \"PULocationID\" int NULL,\n",
    "            \"DOLocationID\" int NULL,\n",
    "            payment_type int NULL,\n",
    "            fare_amount float NULL,\n",
    "            extra float NULL,\n",
    "            mta_tax float NULL,\n",
    "            tip_amount float NULL,\n",
    "            tolls_amount float NULL,\n",
    "            improvement_surcharge float NULL,\n",
    "            total_amount float NULL,\n",
    "            congestion_surcharge varchar(50) NULL\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "\n",
    "    print(f\"Table {color}_taxies created (or already exists).\")\n",
    "\n",
    "    # Step 6: Load CSV data into the table using PostgreSQL's COPY command\n",
    "    print(len(csv_data))\n",
    "    csv_copy_io = io.StringIO(csv_data)\n",
    "    \n",
    "    copy_sql = f\"COPY {color}_taxies FROM STDIN WITH CSV HEADER\"\n",
    "    cursor.copy_expert(copy_sql, csv_copy_io)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Data loaded successfully into the green_taxies table!\")\n",
    "\n",
    "for color in [\"fhv\"]:\n",
    "    for year in [2019, 2020]:\n",
    "        for month in [\"0\" + str(x) if len(str(x)) == 1 else str(x) for x in list(range(1,13))]:\n",
    "            load_data(f\"{color}_tripdata_{year}-{month}.csv.gz\", color)\n",
    "#                         https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ed8ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = \"1,2019-01-01 00:46:40,2019-01-01 00:53:20,1,1.50,1,N,151,239,1,7,0.5,0.5,1.65,0,0.3,9.95,\".split(sep=\",\")\n",
    "cols = \"VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge\".split(sep=\",\")\n",
    "len(st), len(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32064258",
   "metadata": {},
   "source": [
    "#### Analytics questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277e033",
   "metadata": {},
   "source": [
    "Question 5. Taxi Quarterly Revenue Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b79672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30545cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a4582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff2adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb073b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d07c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fcffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (de_zoomcamp)",
   "language": "python",
   "name": "de_zoomcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
